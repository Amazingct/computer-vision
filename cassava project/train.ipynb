{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba817871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "home = 'A:\\projects\\computer-vision\\cassava project'  # Project Directory\n",
    "\n",
    "os.chdir(home)\n",
    "\n",
    "labels = [{'name': 'licence', 'id': 1}]\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'my cassava detection model'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "path_to_images = os.path.join('Datasets', 'licence')\n",
    "\n",
    "paths = \n",
    "{\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow', 'scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow', 'models', 'tfmodels'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'annotations'),\n",
    "    'IMAGE_PATH': path_to_images,\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'models', 'pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'models', CUSTOM_MODEL_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'models', CUSTOM_MODEL_NAME, 'export'),\n",
    "    'TFJS_PATH': os.path.join('Tensorflow', 'models', CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
    "    'TFLITE_PATH': os.path.join('Tensorflow', 'models', CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
    "    'PROTOC_PATH': os.path.join('Tensorflow', 'protoc')\n",
    "}\n",
    "\n",
    "files = \n",
    "{\n",
    "\n",
    "    'PIPELINE_CONFIG': os.path.join('Tensorflow', 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccacba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        os.system('mkdir -p {}'.format(path))\n",
    "        \n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    os.system('git clone https://github.com/tensorflow/models {}'.format(paths['APIMODEL_PATH']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68322332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..........................................................................] 1468733 / 1468733"
     ]
    }
   ],
   "source": [
    "# PROTOC and TensorFlow Object Detection Download\n",
    "url = \"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "\n",
    "# Download protoc\n",
    "if os.name=='posix':\n",
    "    os.system('brew install protobuf-c')\n",
    "    os.system('cd Tensorflow/models/tfmodels/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .')\n",
    "else:\n",
    "    wget.download(url)\n",
    "    # Move nd unzip\n",
    "    os.system('move protoc-3.15.6-win64.zip {}'.format(paths['PROTOC_PATH']))\n",
    "    os.system('cd {} && tar -xf protoc-3.15.6-win64.zip'.format(paths['PROTOC_PATH']))\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
    "    os.system('cd Tensorflow/models/tfmodels/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install')\n",
    "    os.system('cd Tensorflow/models/tfmodels/research/slim && pip install -e .')\n",
    "    \n",
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders','model_builder_tf2_test.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0535bc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify Installation\n",
    "os.system('pip install tensorflow pyyaml && python {}'.format(VERIFICATION_SCRIPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8550c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 20515344 / 20515344"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    import wget\n",
    "    wget.download(url='{}'.format(PRETRAINED_MODEL_URL))\n",
    "    os.system('mv {} {}'.format(PRETRAINED_MODEL_NAME+'.tar.gz',paths['PRETRAINED_MODEL_PATH']))\n",
    "    os.system('cd {} && tar -zxvf {}'.format(paths['PRETRAINED_MODEL_PATH'],PRETRAINED_MODEL_NAME+'.tar.gz'))\n",
    "else:\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    os.system('move {} {}'.format(PRETRAINED_MODEL_NAME + '.tar.gz', paths['PRETRAINED_MODEL_PATH']))\n",
    "    os.system('cd {} && tar -zxvf {}'.format(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME + '.tar.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb92bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label map\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1295a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytz\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Installing collected packages: pytz\n",
      "Successfully installed pytz-2021.3\n"
     ]
    }
   ],
   "source": [
    "os.system('git clone https://github.com/nicknochnack/GenerateTFRecord {}'.format(paths['SCRIPTS_PATH']))\n",
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa0d645c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tfrecords (test and train data) using nicknochnack script\n",
    "#os.system('git clone https://github.com/nicknochnack/GenerateTFRecord {}'.format(paths['SCRIPTS_PATH']))\n",
    "os.system(\"python {} -x {} -l {} -o {}\".format(files['TF_RECORD_SCRIPT'], os.path.join(paths['IMAGE_PATH'], 'train'),files['LABELMAP'],os.path.join(paths['ANNOTATION_PATH'], 'train.record')))\n",
    "os.system(\"python {} -x {} -l {} -o {}\".format(files['TF_RECORD_SCRIPT'], os.path.join(paths['IMAGE_PATH'], 'test'),files['LABELMAP'],os.path.join(paths['ANNOTATION_PATH'], 'test.record')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0546eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy model config file from downloded pre-trained model intomy own model folder\n",
    "\n",
    "if os.name =='posix':\n",
    "    os.system('cp ' + os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME,'pipeline.config') + \" \" + os.path.join(paths['CHECKPOINT_PATH']))\n",
    "else:\n",
    "    os.system('copy ' + os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME,'pipeline.config') + \" \" + os.path.join(paths['CHECKPOINT_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29428b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ssd {\n",
      "  num_classes: 90\n",
      "  image_resizer {\n",
      "    fixed_shape_resizer {\n",
      "      height: 320\n",
      "      width: 320\n",
      "    }\n",
      "  }\n",
      "  feature_extractor {\n",
      "    type: \"ssd_mobilenet_v2_fpn_keras\"\n",
      "    depth_multiplier: 1.0\n",
      "    min_depth: 16\n",
      "    conv_hyperparams {\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 3.9999998989515007e-05\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        random_normal_initializer {\n",
      "          mean: 0.0\n",
      "          stddev: 0.009999999776482582\n",
      "        }\n",
      "      }\n",
      "      activation: RELU_6\n",
      "      batch_norm {\n",
      "        decay: 0.996999979019165\n",
      "        scale: true\n",
      "        epsilon: 0.0010000000474974513\n",
      "      }\n",
      "    }\n",
      "    use_depthwise: true\n",
      "    override_base_feature_extractor_hyperparams: true\n",
      "    fpn {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "      additional_layer_depth: 128\n",
      "    }\n",
      "  }\n",
      "  box_coder {\n",
      "    faster_rcnn_box_coder {\n",
      "      y_scale: 10.0\n",
      "      x_scale: 10.0\n",
      "      height_scale: 5.0\n",
      "      width_scale: 5.0\n",
      "    }\n",
      "  }\n",
      "  matcher {\n",
      "    argmax_matcher {\n",
      "      matched_threshold: 0.5\n",
      "      unmatched_threshold: 0.5\n",
      "      ignore_thresholds: false\n",
      "      negatives_lower_than_unmatched: true\n",
      "      force_match_for_each_row: true\n",
      "      use_matmul_gather: true\n",
      "    }\n",
      "  }\n",
      "  similarity_calculator {\n",
      "    iou_similarity {\n",
      "    }\n",
      "  }\n",
      "  box_predictor {\n",
      "    weight_shared_convolutional_box_predictor {\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 3.9999998989515007e-05\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          random_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.009999999776482582\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.996999979019165\n",
      "          scale: true\n",
      "          epsilon: 0.0010000000474974513\n",
      "        }\n",
      "      }\n",
      "      depth: 128\n",
      "      num_layers_before_predictor: 4\n",
      "      kernel_size: 3\n",
      "      class_prediction_bias_init: -4.599999904632568\n",
      "      share_prediction_tower: true\n",
      "      use_depthwise: true\n",
      "    }\n",
      "  }\n",
      "  anchor_generator {\n",
      "    multiscale_anchor_generator {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "      anchor_scale: 4.0\n",
      "      aspect_ratios: 1.0\n",
      "      aspect_ratios: 2.0\n",
      "      aspect_ratios: 0.5\n",
      "      scales_per_octave: 2\n",
      "    }\n",
      "  }\n",
      "  post_processing {\n",
      "    batch_non_max_suppression {\n",
      "      score_threshold: 9.99999993922529e-09\n",
      "      iou_threshold: 0.6000000238418579\n",
      "      max_detections_per_class: 100\n",
      "      max_total_detections: 100\n",
      "      use_static_shapes: false\n",
      "    }\n",
      "    score_converter: SIGMOID\n",
      "  }\n",
      "  normalize_loss_by_num_matches: true\n",
      "  loss {\n",
      "    localization_loss {\n",
      "      weighted_smooth_l1 {\n",
      "      }\n",
      "    }\n",
      "    classification_loss {\n",
      "      weighted_sigmoid_focal {\n",
      "        gamma: 2.0\n",
      "        alpha: 0.25\n",
      "      }\n",
      "    }\n",
      "    classification_weight: 1.0\n",
      "    localization_weight: 1.0\n",
      "  }\n",
      "  encode_background_as_zeros: true\n",
      "  normalize_loc_loss_by_codesize: true\n",
      "  inplace_batchnorm_update: true\n",
      "  freeze_batchnorm: false\n",
      "}\n",
      ", 'train_config': batch_size: 128\n",
      "data_augmentation_options {\n",
      "  random_horizontal_flip {\n",
      "  }\n",
      "}\n",
      "data_augmentation_options {\n",
      "  random_crop_image {\n",
      "    min_object_covered: 0.0\n",
      "    min_aspect_ratio: 0.75\n",
      "    max_aspect_ratio: 3.0\n",
      "    min_area: 0.75\n",
      "    max_area: 1.0\n",
      "    overlap_thresh: 0.0\n",
      "  }\n",
      "}\n",
      "sync_replicas: true\n",
      "optimizer {\n",
      "  momentum_optimizer {\n",
      "    learning_rate {\n",
      "      cosine_decay_learning_rate {\n",
      "        learning_rate_base: 0.07999999821186066\n",
      "        total_steps: 50000\n",
      "        warmup_learning_rate: 0.026666000485420227\n",
      "        warmup_steps: 1000\n",
      "      }\n",
      "    }\n",
      "    momentum_optimizer_value: 0.8999999761581421\n",
      "  }\n",
      "  use_moving_average: false\n",
      "}\n",
      "fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
      "num_steps: 50000\n",
      "startup_delay_steps: 0.0\n",
      "replicas_to_aggregate: 8\n",
      "max_number_of_boxes: 100\n",
      "unpad_groundtruth_tensors: false\n",
      "fine_tune_checkpoint_type: \"classification\"\n",
      "fine_tune_checkpoint_version: V2\n",
      ", 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      ", 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
      "use_moving_averages: false\n",
      ", 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "# get my model config and edit it: Update Config For Transfer Learning\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4400b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW CONFIG: model {\n",
      "  ssd {\n",
      "    num_classes: 1\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 320\n",
      "        width: 320\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
      "      depth_multiplier: 1.0\n",
      "      min_depth: 16\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 4e-05\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          random_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.01\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.997\n",
      "          scale: true\n",
      "          epsilon: 0.001\n",
      "        }\n",
      "      }\n",
      "      use_depthwise: true\n",
      "      override_base_feature_extractor_hyperparams: true\n",
      "      fpn {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        additional_layer_depth: 128\n",
      "      }\n",
      "    }\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "        use_matmul_gather: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      weight_shared_convolutional_box_predictor {\n",
      "        conv_hyperparams {\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 4e-05\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            random_normal_initializer {\n",
      "              mean: 0.0\n",
      "              stddev: 0.01\n",
      "            }\n",
      "          }\n",
      "          activation: RELU_6\n",
      "          batch_norm {\n",
      "            decay: 0.997\n",
      "            scale: true\n",
      "            epsilon: 0.001\n",
      "          }\n",
      "        }\n",
      "        depth: 128\n",
      "        num_layers_before_predictor: 4\n",
      "        kernel_size: 3\n",
      "        class_prediction_bias_init: -4.6\n",
      "        share_prediction_tower: true\n",
      "        use_depthwise: true\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      multiscale_anchor_generator {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        anchor_scale: 4.0\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        scales_per_octave: 2\n",
      "      }\n",
      "    }\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-08\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "        use_static_shapes: false\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    loss {\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      classification_loss {\n",
      "        weighted_sigmoid_focal {\n",
      "          gamma: 2.0\n",
      "          alpha: 0.25\n",
      "        }\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    encode_background_as_zeros: true\n",
      "    normalize_loc_loss_by_codesize: true\n",
      "    inplace_batchnorm_update: true\n",
      "    freeze_batchnorm: false\n",
      "  }\n",
      "}\n",
      "train_config {\n",
      "  batch_size: 4\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_crop_image {\n",
      "      min_object_covered: 0.0\n",
      "      min_aspect_ratio: 0.75\n",
      "      max_aspect_ratio: 3.0\n",
      "      min_area: 0.75\n",
      "      max_area: 1.0\n",
      "      overlap_thresh: 0.0\n",
      "    }\n",
      "  }\n",
      "  sync_replicas: true\n",
      "  optimizer {\n",
      "    momentum_optimizer {\n",
      "      learning_rate {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 0.08\n",
      "          total_steps: 50000\n",
      "          warmup_learning_rate: 0.026666\n",
      "          warmup_steps: 1000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint: \"Tensorflow\\\\models\\\\pre-trained-models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\\\checkpoint\\\\ckpt-0\"\n",
      "  num_steps: 50000\n",
      "  startup_delay_steps: 0.0\n",
      "  replicas_to_aggregate: 8\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  fine_tune_checkpoint_version: V2\n",
      "}\n",
      "train_input_reader {\n",
      "  label_map_path: \"Tensorflow\\\\annotations\\\\label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow\\\\annotations\\\\train.record\"\n",
      "  }\n",
      "}\n",
      "eval_config {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "}\n",
      "eval_input_reader {\n",
      "  label_map_path: \"Tensorflow\\\\annotations\\\\label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow\\\\annotations\\\\test.record\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "\n",
    "# editing\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME,'checkpoint', 'ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n",
    "\n",
    "# saving\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
    "    print('NEW CONFIG:', config_text)\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466a299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gin-config in a:\\anaconda\\envs\\computer-vision\\lib\\site-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL!pip install gin\n",
    "!pip install gin-config\n",
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=30000\".format(TRAINING_SCRIPT,paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n",
    "os.chdir(home)\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25115234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gin\n",
      "  Using cached gin-0.1.006.tar.bz2 (3.0 kB)\n",
      "Building wheels for collected packages: gin\n",
      "  Building wheel for gin (setup.py): started\n",
      "  Building wheel for gin (setup.py): finished with status 'done'\n",
      "  Created wheel for gin: filename=gin-0.1.6-py3-none-any.whl size=3379 sha256=40433dae5fecf03551ffc98a7a6f8fb413a0c389d288fdfa53bc28d2887e161c\n",
      "  Stored in directory: c:\\users\\amazing\\appdata\\local\\pip\\cache\\wheels\\fc\\fc\\6d\\cff8c43a37f5fd399df0216503dac7fbc985f0997e3bb011be\n",
      "Successfully built gin\n",
      "Installing collected packages: gin\n",
      "Successfully installed gin-0.1.6\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee1960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
